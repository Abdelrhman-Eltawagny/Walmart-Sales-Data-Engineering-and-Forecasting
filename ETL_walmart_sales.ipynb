{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4097568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51500c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = 'pipeline.log' , format = '%(asctime)s - %(levelname)s - %(message)s' , level = logging.DEBUG )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deeaf323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction():\n",
    "        \"\"\"\n",
    "    Extracts Walmart sales data from a CSV file into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing raw Walmart sales data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the extracted sales data.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file_path does not exist.\n",
    "        pd.errors.ParserError: If the CSV is malformed or unreadable.\n",
    "    \"\"\"\n",
    "    logging.info('Starting the extraction process')\n",
    "    try:\n",
    "        return pd.read_csv('Walmart.csv')\n",
    "        logging.info('Successfully extracted Walmart data')\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f'File not found: {e}')\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f'Error during Walmart file extraction: {e}') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09064773",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_sales = extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecfd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(df):\n",
    "        \"\"\"\n",
    "    Transforms raw Walmart sales data into a star schema format and prepares dimension and fact tables.\n",
    "\n",
    "    Steps performed:\n",
    "        - Extracts and formats date and time components.\n",
    "        - Creates surrogate keys for dimension tables.\n",
    "        - Constructs dimension tables: Store, Category, Payment, and Date.\n",
    "        - Creates a fact table linking all dimension tables.\n",
    "        - Adds a unified datetime column for analytics and machine learning purposes.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw extracted Walmart sales data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]: \n",
    "            - fact_walmart_sales: Fact table with keys and measurable data.\n",
    "            - DimStore: Dimension table for store information.\n",
    "            - DimCategory: Dimension table for product categories.\n",
    "            - DimPayment: Dimension table for payment methods.\n",
    "            - DimDate: Dimension table for date and time details.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If expected columns are missing in the input DataFrame.\n",
    "        ValueError: If data conversion or datetime formatting fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('Start data cleaning process')\n",
    "    \n",
    "    try:\n",
    "        df.dropna(inplace = True)\n",
    "        df.drop_duplicates(inplace = True)\n",
    "        logging.info('Dropped missing values and duplicates in data')\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f'Error during cleaning data: {e}')\n",
    "    \n",
    "    try:\n",
    "        df['quantity'] = df['quantity'].astype(int)\n",
    "        df['unit_price'] = df['unit_price'].replace('[\\$,]' , '' , regex = True).astype(float)\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n",
    "        df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')\n",
    "        \n",
    "        logging.info('Convert quantity, unit_price , date and time column into correct type')\n",
    "    \n",
    "    except ValueError as e:\n",
    "        logging.error(\"ValueError during numeric conversion: %s\", e)\n",
    "     \n",
    "    try:\n",
    "        df['total_price'] = df['unit_price'] * df['quantity']\n",
    "        df['revenue_per_item'] = df['total_price'] / df['quantity']\n",
    "        df['profit'] = round(df['total_price'] * df['profit_margin'] , 2)\n",
    "        \n",
    "    \n",
    "        df['DateTime'] = df['date'].dt.strftime('%Y-%m-%d') + ' ' + df['time'].dt.strftime('%H:%M:%S')\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "        df['day'] = df['DateTime'].dt.day\n",
    "        df['day_of_week'] = df['DateTime'].dt.day_name()\n",
    "        df['month'] = df['DateTime'].dt.month\n",
    "        df['year'] = df['DateTime'].dt.year\n",
    "        logging.info('Create new features correctly')\n",
    "    \n",
    "    except KeyError as e:\n",
    "        logging.error(\"KeyError: Column not found - %s\", e)\n",
    "        \n",
    "    # Create dimension tables\n",
    "    DimStore = df[['Branch', 'City']].drop_duplicates().reset_index(drop=True)\n",
    "    DimStore['store_id'] = DimStore.index + 1\n",
    "\n",
    "    DimCategory = df[['category']].drop_duplicates().reset_index(drop=True)\n",
    "    DimCategory['category_id'] = DimCategory.index + 10001\n",
    "\n",
    "    DimPayment = df[['payment_method']].drop_duplicates().reset_index(drop=True)\n",
    "    DimPayment['payment_id'] = DimPayment.index + 20001\n",
    "\n",
    "    DimDate = df[['DateTime', 'year', 'month', 'day', 'day_of_week']].drop_duplicates().reset_index(drop=True)\n",
    "    DimDate['date_id'] = DimDate.index + 30001\n",
    "\n",
    "    # Create fact table\n",
    "    fact_sales = df.copy()\n",
    "    fact_sales = fact_sales.merge(DimStore, on=['Branch', 'City'], how='left')\n",
    "    fact_sales = fact_sales.merge(DimCategory, on='category', how='left')\n",
    "    fact_sales = fact_sales.merge(DimPayment, on='payment_method', how='left')\n",
    "    fact_sales = fact_sales.merge(DimDate, on=['DateTime', 'year' , 'month', 'day', 'day_of_week'], how='left')\n",
    "\n",
    "    fact_walmart_sales = fact_sales[['invoice_id','store_id', 'category_id', 'payment_id', 'date_id',\n",
    "                                'rating', 'unit_price', 'quantity', 'profit_margin',\n",
    "                                'total_price', 'revenue_per_item', 'profit']]\n",
    "\n",
    "    logging.info('Transformation complete')\n",
    "    return fact_walmart_sales, DimStore, DimCategory, DimPayment, DimDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f918f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fact_sales, DimStore, DimCategory, DimPayment, DimDate):\n",
    "    \"\"\"\n",
    "    Loads the dimension and fact tables into an SQLite database and exports data marts as CSV files.\n",
    "\n",
    "    Steps performed:\n",
    "        - Saves all tables into an SQLite database (`walmart.db`).\n",
    "        - Creates and exports a Machine Learning data mart (date vs profit).\n",
    "        - Creates and exports an Analytics data mart with detailed transactional data.\n",
    "\n",
    "    Args:\n",
    "        fact_sales (pd.DataFrame): Fact table with sales metrics and foreign keys.\n",
    "        DimStore (pd.DataFrame): Dimension table for store details.\n",
    "        DimCategory (pd.DataFrame): Dimension table for category data.\n",
    "        DimPayment (pd.DataFrame): Dimension table for payment methods.\n",
    "        DimDate (pd.DataFrame): Dimension table with date-time breakdown.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Side Effects:\n",
    "        - Writes to SQLite database (`walmart.db`).\n",
    "        - Saves CSV files: `ml_data_mart.csv`, `analytics_data_mart.csv`.\n",
    "\n",
    "    Raises:\n",
    "        sqlite3.DatabaseError: If a database error occurs during table creation or querying.\n",
    "        Exception: For general errors during the load process.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        conn = sqlite3.connect('walmart.db')\n",
    "\n",
    "        # Save dimension and fact tables\n",
    "        DimStore.to_sql('DimStore', conn, index=False, if_exists='replace')\n",
    "        DimCategory.to_sql('DimCategory', conn, index=False, if_exists='replace')\n",
    "        DimPayment.to_sql('DimPayment', conn, index=False, if_exists='replace')\n",
    "        DimDate.to_sql('DimDate', conn, index=False, if_exists='replace')\n",
    "        fact_sales.to_sql('fact_walmart_sales', conn, index=False, if_exists='replace')\n",
    "        \n",
    "        logging.info(\"All tables saved to SQLite successfully\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during loading data to SQLite: {e}\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            ml_query = \"\"\"\n",
    "            SELECT D.DateTime , F.profit\n",
    "            FROM fact_walmart_sales F INNER JOIN DimDate D on F.date_id = D.date_id\n",
    "            \"\"\"\n",
    "        \n",
    "            ml_data_mart = pd.read_sql(ml_query , conn)\n",
    "            ml_data_mart.to_csv('ml_data_mart.csv')\n",
    "        \n",
    "            analytics_query = \"\"\"\n",
    "            SELECT F.invoice_id, F.quantity, F.total_price, F.profit, C.category, F.rating, P.payment_method, D.Datetime  \n",
    "            FROM fact_walmart_sales F INNER JOIN DimCategory C on F.category_id = C.category_id\n",
    "            INNER JOIN DimPayment P ON F.payment_id = P.payment_id\n",
    "            INNER JOIN DimDate D ON F.date_id = D.date_id\n",
    "            \"\"\"\n",
    "            df_analytics = pd.read_sql(analytics_query , conn)\n",
    "            df_analytics.to_csv('analytics_data_mart.csv')\n",
    "        \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            logging.info(\"Data mart saved successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during loading data mart: {e}\")\n",
    "        \n",
    "fact_sales, DimStore, DimCategory, DimPayment, DimDate = transformation(walmart_sales)\n",
    "load_data(fact_sales, DimStore, DimCategory, DimPayment, DimDate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
